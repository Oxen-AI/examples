{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00acdb34",
   "metadata": {},
   "source": [
    "## Label file creation + reorganization for ActiveFire dataset\n",
    "\n",
    "The output of this dataset is already included in the latest version of the repository, but to recreate, first clone the Oxen repository: \n",
    "\n",
    "```bash oxen clone https://hub.oxen.ai/ba/ActiveFire```\n",
    "\n",
    "Then run this file from the root of the ActiveFire directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f590142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7a4fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glob existing files to get counts per directory after unpacking\n",
    "landsat = glob.glob('data/landsat_patches/*')\n",
    "manual = glob.glob('data/manual_annotations_patches/*')\n",
    "masks = glob.glob('data/masks_patches/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "386513af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landsat patches: 9045\n",
      "Manually annotated patches: 100\n",
      "Masks annotated patches: 1098\n"
     ]
    }
   ],
   "source": [
    "print(f\"Landsat patches: {len(landsat)}\")\n",
    "print(f\"Manually annotated patches: {len(manual)}\")\n",
    "print(f\"Masks annotated patches: {len(masks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2646109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect paths for each file / label type for matching to associate data with labels\n",
    "data = pd.DataFrame()\n",
    "landsat_paths = []\n",
    "mask_paths = []\n",
    "manual_paths = []\n",
    "for path in landsat: \n",
    "    landsat_paths.append(path.split('/')[2])\n",
    "    \n",
    "for path in manual:\n",
    "    manual_paths.append(path.split('/')[2])\n",
    "\n",
    "for path in masks:\n",
    "    mask_paths.append(path.split('/')[2])\n",
    "\n",
    "landsat_paths = pd.Series(landsat_paths)\n",
    "manual_paths = pd.Series(manual_paths)\n",
    "mask_paths = pd.Series(mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7ab8fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kumar 391\n",
      "Intersection 118\n",
      "Murphy 164\n",
      "Schroeder 227\n",
      "Voting 198\n"
     ]
    }
   ],
   "source": [
    "# Separate out the 5 different non-manual masking methods and get their counts\n",
    "kumar = mask_paths[mask_paths.str.contains('Kumar')]\n",
    "intersection = mask_paths[mask_paths.str.contains('Intersection')]\n",
    "murphy = mask_paths[mask_paths.str.contains('Murphy')]\n",
    "schroeder = mask_paths[mask_paths.str.contains('Schroeder')]\n",
    "voting = mask_paths[mask_paths.str.contains('Voting')]\n",
    "\n",
    "print(\"Kumar\", len(kumar))\n",
    "print(\"Intersection\", len(intersection))\n",
    "print(\"Murphy\", len(murphy))\n",
    "print(\"Schroeder\", len(schroeder))\n",
    "print(\"Voting\", len(voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c0061c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all to dataframes to make new columns\n",
    "landsat = pd.DataFrame(landsat_paths)\n",
    "kumar = pd.DataFrame(kumar)\n",
    "intersection = pd.DataFrame(intersection)\n",
    "murphy = pd.DataFrame(murphy)\n",
    "schroeder = pd.DataFrame(schroeder)\n",
    "voting = pd.DataFrame(voting)\n",
    "manual = pd.DataFrame(manual_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "103b83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to slice out the unique additive to each path, leaving only the matchable scene_ids\n",
    "def get_scene_name(path, key):\n",
    "    path = path.replace(key, '')\n",
    "    return path \n",
    "\n",
    "# Landsat paths are just the scene ids, so no need to process\n",
    "keys = {\n",
    "    'kumar': 'Kumar-Roy_',\n",
    "    'intersection': 'Intersection_',\n",
    "    'murphy': 'Murphy_',\n",
    "    'schroeder': 'Schroeder_',\n",
    "    'voting': 'Voting_',\n",
    "    'manual': 'v1_',\n",
    "    'landsat': ''\n",
    "}\n",
    "\n",
    "dfs = {'landsat': landsat, 'kumar': kumar, 'intersection': intersection, \n",
    "         'murphy': murphy, \n",
    "         'schroeder': schroeder, \n",
    "         'voting': voting, \n",
    "         'manual': manual}\n",
    "\n",
    "for key, df in dfs.items():\n",
    "    df['patch_id'] = df[0].apply(lambda x: get_scene_name(x, keys[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0c493942",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfs.items(): \n",
    "    df.rename(columns={0: f'{key}_path'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3bee80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all dataframes together on the common patch_id column, starting with landsat as the source of truth for left join\n",
    "merged = dfs['landsat']\n",
    "for key, df in dfs.items(): \n",
    "    if key != 'landsat':\n",
    "        merged = pd.merge(merged, df, on='patch_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "af16b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ landsat count: 9045 equals original count of 9045\n",
      "✅ kumar count: 391 equals original count of 391\n",
      "✅ intersection count: 118 equals original count of 118\n",
      "✅ murphy count: 164 equals original count of 164\n",
      "✅ schroeder count: 227 equals original count of 227\n",
      "✅ voting count: 198 equals original count of 198\n",
      "✅ manual count: 100 equals original count of 100\n"
     ]
    }
   ],
   "source": [
    "# Ensure merge happened properly and all paths in sub-files matched a landsat file \n",
    "for key, df in dfs.items():\n",
    "    merged_count = (merged[f'{key}_path'].isna() == False).sum()\n",
    "    original_count = len(df)\n",
    "    assert merged_count == original_count, f\"❌ Error with {key} merge. Merged count: {merged_count}, Original count: {original_count}\"\n",
    "    print(f\"✅ {key} count: {(merged[f'{key}_path'].isna() == False).sum()} equals original count of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "22f86baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scene id for merging with metadata before changing column identifiers \n",
    "merged['scene_id'] = merged.landsat_path.apply(lambda x: \"_\".join(x.split('_')[:-1]))\n",
    "\n",
    "# Generate the full correct relative paths - these columns have different base folders\n",
    "merged['landsat_path'] = merged.landsat_path.apply(lambda x: 'data/landsat_patches/'+x if x==x else x)\n",
    "merged['manual_path'] = merged.manual_path.apply(lambda x: 'data/manual_annotations_patches/'+x if x==x else x)\n",
    "\n",
    "for key, df in dfs.items():\n",
    "    if key not in ['landsat', 'manual']:\n",
    "        merged[f'{key}_path'] = merged[f'{key}_path'].apply(lambda x: 'data/masks_patches/'+x if x==x else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ee76a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with scene-level metadata \n",
    "metadata = pd.read_csv('labels/images202009.csv', sep=';')\n",
    "final_merged = pd.merge(merged, metadata, left_on = 'scene_id', right_on='productId', how='left')\n",
    "\n",
    "final_merged.to_csv(\"labels/labels.csv\", drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
